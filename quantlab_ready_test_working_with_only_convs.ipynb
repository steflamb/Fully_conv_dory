{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2aad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63903750",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vendor/quantlib\n",
    "\n",
    "import quantlib\n",
    "import quantlib.algorithms as qa\n",
    "import quantlib.editing.graphs as qg\n",
    "import quantlib.editing.editing as qe\n",
    "import quantlib.backends.dory as qd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f8dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15963d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(filename,train,calib,size):\n",
    "        with h5py.File(filename, 'r', libver='v112') as h5_file_handle:\n",
    "            if train:\n",
    "              image_train=np.array(h5_file_handle[\"/train/image\"])\n",
    "              full_pose_train=np.array(h5_file_handle[\"/train/xyzyaw_relative\"])\n",
    "              led_status_train=np.array(h5_file_handle[\"/train/led_status\"])\n",
    "              image_points_y=np.array(h5_file_handle[\"/train/image_points_y\"])\n",
    "              image_points_x=np.array(h5_file_handle[\"/train/image_points_x\"])\n",
    "            else:\n",
    "              image_train=np.array(h5_file_handle[\"/test/image\"])\n",
    "              full_pose_train=np.array(h5_file_handle[\"/test/xyzyaw_relative\"])\n",
    "              led_status_train=np.array(h5_file_handle[\"/test/led_status\"])\n",
    "              image_points_y=np.array(h5_file_handle[\"/test/image_points_y\"])\n",
    "              image_points_x=np.array(h5_file_handle[\"/test/image_points_x\"])\n",
    "        x=image_points_y.reshape((-1,1))\n",
    "        y=image_points_y.reshape((-1,1))\n",
    "        sz = 160\n",
    "        X, Y = np.meshgrid(np.arange(sz),np.arange(sz))\n",
    "        # out=np.empty((0,160,160), int)\n",
    "        out =[]\n",
    "        for element in range(image_points_y.shape[0]): \n",
    "          x, y = 150-image_points_y[element],160-image_points_x[element]\n",
    "          D = ((X-x)**2 + (Y-y)**2)**0.5\n",
    "          out_in=((1 - np.tanh((D-5)*0.08))/2).astype(\"float32\")\n",
    "          # out=np.append(out,out_in[None,:,:],axis=0)\n",
    "          out.append(out_in[None,:,:])\n",
    "        if(calib):\n",
    "            im=image_train[0:size]\n",
    "            dist=full_pose_train.reshape((-1,4))[:,0].reshape(-1,1)[0:size]\n",
    "            led=led_status_train.reshape((-1,1))[0:size]\n",
    "            out=np.array(out)[0:size]\n",
    "        else:\n",
    "            im=image_train\n",
    "            dist=full_pose_train.reshape((-1,4))[:,0].reshape(-1,1)\n",
    "            led=led_status_train.reshape((-1,1))\n",
    "            out=np.array(out)\n",
    "        print(im.shape)\n",
    "        print(out.shape)\n",
    "        led=np.tile(np.expand_dims(np.expand_dims(led, axis=-1), axis=-1), [1,160,160])\n",
    "        dist=np.tile(np.expand_dims(np.expand_dims(dist, axis=-1), axis=-1), [1,160,160])\n",
    "        print(dist.shape)\n",
    "        print(led.shape)\n",
    "        y_train=np.concatenate((np.concatenate((out,led),axis=1),dist),axis=1)\n",
    "        print(y_train.shape)\n",
    "        \n",
    "\n",
    "        return [im,y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a30e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.from_numpy(x).int()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f53a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Mcalib = 1024\n",
    "calib_set = get_data(\"./content/datasets/dataset_train.h5\",True,True,8192)\n",
    "# train_set = get_data(\"./content/datasets/dataset_train.h5\",True,False)\n",
    "# train_dataset = MyDataset(train_set[0], train_set[1])\n",
    "calib_dataset = MyDataset(calib_set[0], calib_set[1])\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "calib_dataloader = DataLoader(calib_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd92c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_plot(dataloader):\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(15, 12))\n",
    "    axs = axs.flatten()\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        if i%2==1:\n",
    "          if i >= 12:\n",
    "              break\n",
    "          axs[i-1].imshow(x[0][0],cmap=\"gray\")\n",
    "          axs[i].imshow(y[0][0])\n",
    "          print(\"dist:\",y[0][2][0][0])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2b7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_plot(calib_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071be86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MkModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MkModel, self).__init__()\n",
    "#         activation_class = nn.ReLU\n",
    "#         self.block1 = MkModel.make_standard_convolution_layer(in_channels=1,out_channels=8,kernel_size=3,padding=1,stride=1,activation_class=activation_class)\n",
    "#         self.block2 = MkModel.make_standard_convolution_layer(in_channels=8,out_channels=16,kernel_size=3,padding=1,stride=1,activation_class=activation_class)\n",
    "#         self.poolconv1 = MkModel.make_standard_convolution_layer(in_channels=16,out_channels=16,kernel_size=2,padding=0,stride=2,activation_class=activation_class)\n",
    "#         self.block3 = MkModel.make_standard_convolution_layer(in_channels=16,out_channels=32,kernel_size=3,padding=1,stride=1,activation_class=activation_class)\n",
    "#         self.poolconv2 = MkModel.make_standard_convolution_layer(in_channels=32,out_channels=32,kernel_size=2,padding=0,stride=2,activation_class=activation_class)\n",
    "#         self.block4 = MkModel.make_standard_convolution_layer(in_channels=32,out_channels=64,kernel_size=3,padding=1,stride=1,activation_class=activation_class)\n",
    "#         self.poolconv3 = MkModel.make_standard_convolution_layer(in_channels=64,out_channels=64,kernel_size=2,padding=0,stride=2,activation_class=activation_class)\n",
    "#         self.block5 = MkModel.make_standard_convolution_layer(in_channels=64,out_channels=128,kernel_size=3,padding=1,stride=1,activation_class=activation_class)\n",
    "#         self.block6 = MkModel.make_standard_convolution_layer(in_channels=128,out_channels=128,kernel_size=3,padding=1,stride=1,activation_class=activation_class)\n",
    "#         self.block7 = MkModel.make_standard_convolution_layer(in_channels=128,out_channels=3,kernel_size=3,padding=1,stride=1,activation_class=activation_class)\n",
    "\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def make_standard_convolution_layer(in_channels:      int,\n",
    "#                                             out_channels:     int,\n",
    "#                                             kernel_size:    int,\n",
    "#                                             padding:      int,\n",
    "#                                             stride:       int,\n",
    "#                                             activation_class: type) -> nn.Sequential:\n",
    "\n",
    "#             modules = []\n",
    "\n",
    "#             modules += [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride,padding=padding, bias=False)]\n",
    "#             modules += [nn.BatchNorm2d(out_channels)]\n",
    "#             modules += [activation_class(inplace=True)]\n",
    "\n",
    "#             return nn.Sequential(*modules)\n",
    "    \n",
    "    \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.block1(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.block2(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.poolconv1(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.block3(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.poolconv2(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.block4(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.poolconv3(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.block5(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.block6(x)\n",
    "# #         print(x.shape)\n",
    "#         x = self.block7(x)\n",
    "# #         print(x.shape)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56532378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MkModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MkModel, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(8)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.sep_conv1 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(16)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.bn_pool1 = nn.BatchNorm2d(16)\n",
    "#         self.sep_conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(32)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.bn_pool2 = nn.BatchNorm2d(32)\n",
    "#         self.sep_conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "#         self.bn4 = nn.BatchNorm2d(64)\n",
    "#         self.relu4 = nn.ReLU()\n",
    "#         self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.bn_pool3 = nn.BatchNorm2d(64)\n",
    "#         self.sep_conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "#         self.bn5 = nn.BatchNorm2d(128)\n",
    "#         self.relu5 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, padding=0)\n",
    "#         self.bn6 = nn.BatchNorm2d(128)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "#         self.conv3 = nn.Conv2d(in_channels=128, out_channels=3, kernel_size=1, padding=0)\n",
    "#         self.bn7 = nn.BatchNorm2d(3)\n",
    "#         self.relu7 = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.bn1(self.conv1(x)))\n",
    "#         x = self.relu2(self.bn2(self.sep_conv1(x)))\n",
    "#         x = self.bn_pool1(self.pool1(x))\n",
    "#         x = self.relu3(self.bn3(self.sep_conv2(x)))\n",
    "#         x = self.bn_pool2(self.pool2(x))\n",
    "#         x = self.relu4(self.bn4(self.sep_conv3(x)))\n",
    "#         x = self.bn_pool3(self.pool3(x))\n",
    "#         x = self.relu5(self.bn5(self.sep_conv4(x)))\n",
    "#         x = self.relu6(self.bn6(self.conv2(x)))\n",
    "#         x = self.relu7(self.bn7(self.conv3(x)))\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad5e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MkModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MkModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.sep_conv1 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.sep_conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.sep_conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.sep_conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, padding=0)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=3, kernel_size=1, padding=0)\n",
    "        self.bn7 = nn.BatchNorm2d(3)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu2(self.bn2(self.sep_conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu3(self.bn3(self.sep_conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu4(self.bn4(self.sep_conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.relu5(self.bn5(self.sep_conv4(x)))\n",
    "        x = self.relu6(self.bn6(self.conv2(x)))\n",
    "        x = self.relu7(self.bn7(self.conv3(x)))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dd01a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MkModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MkModel, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(8)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.sep_conv1 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(16)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.bn_pool1 = nn.BatchNorm2d(16)\n",
    "#         self.relupool1 = nn.ReLU()\n",
    "#         self.sep_conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(32)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.bn_pool2 = nn.BatchNorm2d(32)\n",
    "#         self.relupool2 = nn.ReLU()\n",
    "#         self.sep_conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "#         self.bn4 = nn.BatchNorm2d(64)\n",
    "#         self.relu4 = nn.ReLU()\n",
    "#         self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.bn_pool3 = nn.BatchNorm2d(64)\n",
    "#         self.relupool3 = nn.ReLU()\n",
    "#         self.sep_conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "#         self.bn5 = nn.BatchNorm2d(128)\n",
    "#         self.relu5 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, padding=0)\n",
    "#         self.bn6 = nn.BatchNorm2d(128)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "#         self.conv3 = nn.Conv2d(in_channels=128, out_channels=3, kernel_size=1, padding=0)\n",
    "#         self.bn7 = nn.BatchNorm2d(3)\n",
    "#         self.relu7 = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.bn1(self.conv1(x)))\n",
    "#         x = self.relu2(self.bn2(self.sep_conv1(x)))\n",
    "#         x = self.relupool1(self.bn_pool1(self.pool1(x)))\n",
    "#         x = self.relu3(self.bn3(self.sep_conv2(x)))\n",
    "#         x = self.relupool2(self.bn_pool2(self.pool2(x)))\n",
    "#         x = self.relu4(self.bn4(self.sep_conv3(x)))\n",
    "#         x = self.relupool3(self.bn_pool3(self.pool3(x)))\n",
    "#         x = self.relu5(self.bn5(self.sep_conv4(x)))\n",
    "#         x = self.relu6(self.bn6(self.conv2(x)))\n",
    "#         x = self.relu7(self.bn7(self.conv3(x)))\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd1445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MkModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MkModel, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(8)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.sep_conv1 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(16)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.pool1 = nn.AdaptiveMaxPool2d((80,80))\n",
    "#         self.sep_conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "#         self.bn3 = nn.BatchNorm2d(32)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.pool2 = nn.AdaptiveMaxPool2d((40,40))\n",
    "#         self.sep_conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "#         self.bn4 = nn.BatchNorm2d(64)\n",
    "#         self.relu4 = nn.ReLU()\n",
    "#         self.pool3 = nn.AdaptiveMaxPool2d((20,20))\n",
    "#         self.sep_conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "#         self.bn5 = nn.BatchNorm2d(128)\n",
    "#         self.relu5 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, padding=0)\n",
    "#         self.bn6 = nn.BatchNorm2d(128)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "#         self.conv3 = nn.Conv2d(in_channels=128, out_channels=3, kernel_size=1, padding=0)\n",
    "#         self.bn7 = nn.BatchNorm2d(3)\n",
    "#         self.relu7 = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.bn1(self.conv1(x)))\n",
    "#         x = self.relu2(self.bn2(self.sep_conv1(x)))\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.relu3(self.bn3(self.sep_conv2(x)))\n",
    "#         x = self.pool2(x)\n",
    "#         x = self.relu4(self.bn4(self.sep_conv3(x)))\n",
    "#         x = self.pool3(x)\n",
    "#         x = self.relu5(self.bn5(self.sep_conv4(x)))\n",
    "#         x = self.relu6(self.bn6(self.conv2(x)))\n",
    "#         x = self.relu7(self.bn7(self.conv3(x)))\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a6266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MkModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43b64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decompose(y_true, y_pred):\n",
    "    # print(y_true.shape)\n",
    "    # print(y_true.shape)\n",
    "    # plt.imshow(y_true[0][0].cpu(),cmap=\"gray\")\n",
    "    # plt.show\n",
    "    y_true_pos = torch.nn.functional.avg_pool2d(y_true[:,0,:,:], 8)\n",
    "    y_true_dis = torch.nn.functional.avg_pool2d(y_true[:,2,:,:], 8)\n",
    "    y_true_led = torch.nn.functional.avg_pool2d(y_true[:,1,:,:], 8)\n",
    "#     y_true_pos = y_true[:,0,:,:]\n",
    "#     y_true_dis = y_true[:,2,:,:]\n",
    "#     y_true_led = y_true[:,1,:,:]\n",
    "    y_pred_pos = y_pred[:,0,:,:]\n",
    "    y_pred_dis = y_pred[:,2,:,:]\n",
    "    y_pred_led = y_pred[:,1,:,:]\n",
    "#     print(y_pred_pos.shape)\n",
    "    return y_true_pos, y_true_led, y_true_dis, y_pred_pos, y_pred_led, y_pred_dis\n",
    "\n",
    "def pos_loss(y_true, y_pred):\n",
    "    pos_true, led_true, dis_true, pos_pred, led_pred, dis_pred = decompose(y_true, y_pred)\n",
    "    return torch.mean((pos_true - pos_pred) ** 2)\n",
    "\n",
    "def led_loss(y_true, y_pred):\n",
    "    pos_true, led_true, dis_true, pos_pred, led_pred, dis_pred = decompose(y_true, y_pred)\n",
    "    led_sse = torch.sum(((led_true - led_pred) ** 2) * pos_true)\n",
    "    return led_sse / torch.clamp(torch.sum(pos_true), min=0.001)\n",
    "\n",
    "def dis_loss(y_true, y_pred):\n",
    "    pos_true, led_true, dis_true, pos_pred, led_pred, dis_pred = decompose(y_true, y_pred)\n",
    "    dis_true = torch.clamp(dis_true, min=0.1)\n",
    "    dis_ssre = torch.sum((((dis_pred - dis_true) / dis_true) ** 2) * pos_true)\n",
    "    return dis_ssre / torch.clamp(torch.sum(pos_true), min=0.001)\n",
    "\n",
    "def total_loss(y_pred,y_true):\n",
    "    return pos_loss(y_true, y_pred) + 0.01 * dis_loss(y_true, y_pred) + 0.01 * led_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82dbe94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./content/model.h5\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1e90a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()  # set model to evaluation mode\n",
    "\n",
    "fig_in, ax_in = plt.subplots(11, 3, figsize=(30, 110))\n",
    "ax_in = ax_in.flatten()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # get a single batch of data from test dataloader\n",
    "    data = next(iter(calib_dataloader))\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(inputs.float() / 255.0)\n",
    "    outputs = outputs * torch.tensor([1., 1., 3.]).view(1, 3, 1, 1).to(outputs.device)\n",
    "    loss = total_loss(outputs, labels)\n",
    "    test_loss += loss.item()\n",
    "    pos_true, led_true, dis_true, pos_pred, led_pred, dis_pred = decompose(labels,outputs)\n",
    "    for i in range(0,inputs.shape[0],3):\n",
    "        ax_in[i].imshow(inputs[i][0].cpu(),cmap=\"gray\")\n",
    "        ax_in[i+1].imshow(pos_true[i].cpu(),cmap=\"gray\")\n",
    "        ax_in[i+2].imshow(pos_pred[i].cpu(),cmap=\"gray\")\n",
    "    #   \n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab20fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, device, dataloader, verbose=True, integer=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if integer:\n",
    "                outputs = model(inputs.float())\n",
    "            else:\n",
    "                outputs = model(inputs.float() / 255.0)\n",
    "            outputs = outputs * torch.tensor([1., 1., 3.]).view(1, 3, 1, 1).to(outputs.device)\n",
    "            loss = total_loss(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "        print(f\"Test loss: {test_loss/len(dataloader)}\")\n",
    "    return test_loss/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200864d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Trace floating-point model graph and print it in human-readable format\n",
    "\n",
    "# Symbolic trace of the graph\n",
    "model_fp = qg.fx.quantlib_symbolic_trace(root=model)\n",
    "\n",
    "# Print the graph in tabular format\n",
    "model_fp.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929472fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#float 2 fake\n",
    "f2fconverter = qe.float2fake.F2F8bitPACTRoundingConverter()\n",
    "model_fq = f2fconverter(model_fp)\n",
    "# set validation state\n",
    "model_fq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625abc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the graph in tabular format\n",
    "model_fq.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5d687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collect statistics about the floating-point `Tensor`s passing through the quantisers, so that we can better fit the quantisers' hyper-parameters\n",
    "with qe.float2fake.calibration(model_fq):\n",
    "    acc = validate(model_fq, device, calib_dataloader)\n",
    "\n",
    "# adds rounding to all PACT operators\n",
    "rounder =  qe.float2fake.F2F8bitPACTRounder()\n",
    "model_fq_rounded = rounder(model_fq)\n",
    "\n",
    "model_fq_rounded.to(device)\n",
    "model_fq_rounded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5c7d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_fq.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd77476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_set = get_data(\"./content/datasets/dataset_test.h5\",False,False,1024)\n",
    "# valid_set = get_data(\"./content/datasets/dataset_test.h5\",False,False,0)\n",
    "valid_dataset = MyDataset(valid_set[0], valid_set[1])\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27252b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get exaple input\n",
    "# x, _ = next(iter(valid_dataloader))\n",
    "# x = x[0].unsqueeze(0)\n",
    "x = torch.ones((1, 1, 160, 160), dtype=torch.uint8)\n",
    "print(x.dtype)\n",
    "\n",
    "# convert to TrueQuantized with default 24-bit converter\n",
    "f2tconverter = qe.f2t.F2T24bitConverter()\n",
    "model_tq = f2tconverter(model_fq_rounded, {'x': {'shape': x.shape, 'scale': torch.tensor((0.0039216,))}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d842c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the graph in tabular format\n",
    "model_tq.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2994a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epsremover = qe.f2t.FinalEpsTunnelRemover()\n",
    "model_tq_removed = epsremover(model_tq)\n",
    "print(model_tq_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebabf0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_dir = 'out'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "doryexporter = qd.onnxexporter.DORYExporter()\n",
    "doryexporter.export(model_tq, x.shape, out_dir)\n",
    "doryexporter.dump_features(model_tq, x, out_dir)\n",
    "doryexporter.export_json_config(BNRelu_bits=64, input_signed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb810e-673e-4c49-a05a-cbceb6d18c85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python vendor/dory/network_generate.py Quantlab PULP.GAP8 out/config_MkModel.json --app_dir out/application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa655f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mgX40, mgY40 = np.meshgrid(np.linspace(0,1,20), np.linspace(0,1,20))\n",
    "def postprocess_simple_batch(labels, outputs):\n",
    "    pos_true, led_true, dis_true, pos_predi, led_predi, dis_predi = decompose(labels,outputs)\n",
    "    pos_truei=pos_true.cpu().detach().numpy()\n",
    "    led_truei=led_true.cpu().detach().numpy()\n",
    "    dis_truei=dis_true.cpu().detach().numpy()\n",
    "    pos_predi=pos_predi.cpu().detach().numpy()\n",
    "    led_predi=led_predi.cpu().detach().numpy()\n",
    "    dis_predi=dis_predi.cpu().detach().numpy()\n",
    "\n",
    "    # a=dis_pred[i]*pos_pred[i]\n",
    "    # a=a.cpu().detach().numpy()\n",
    "    # b=pos_pred[i].cpu().detach().numpy()\n",
    "    # dis_pred_val = np.sum(a)/np.sum(b)\n",
    "    threshold = np.max(pos_predi, axis = (1,2), keepdims = True) * .4\n",
    "    # print(threshold)\n",
    "    pos_predi -= threshold\n",
    "    np.clip(pos_predi, 0, threshold, out = pos_predi)\n",
    "    pos_predj=pos_predi\n",
    "    # print(np.sum(dis_predi * pos_predi, axis=(1,2))/np.sum(pos_predi, axis=(1,2)))\n",
    "    # print(np.sum(dis_truei * pos_truei, axis=(1,2))/np.sum(pos_truei, axis=(1,2)))\n",
    "  \n",
    "    \n",
    "    # print(dis_true)\n",
    "    ret = dict(\n",
    "        x_pred = np.sum(mgX40[np.newaxis,:,:] * pos_predi, axis=(1,2))/np.sum(pos_predi, axis=(1,2)) * 160,\n",
    "        y_pred = np.sum(mgY40[np.newaxis,:,:] * pos_predi, axis=(1,2))/np.sum(pos_predi, axis=(1,2)) * 160,\n",
    "        led_pred = np.sum(led_predi * pos_predj, axis=(1,2))/np.sum(pos_predj, axis=(1,2)),\n",
    "        dis_pred = np.sum(dis_predi * pos_predj, axis=(1,2))/np.sum(pos_predj, axis=(1,2)),\n",
    "        pred_confidence = np.max(pos_predi, axis=(1,2)),\n",
    "        x_true = np.sum(mgX40[np.newaxis,:,:] * pos_truei, axis=(1,2))/np.sum(pos_truei, axis=(1,2)) * 160,\n",
    "        y_true = np.sum(mgY40[np.newaxis,:,:] * pos_truei, axis=(1,2))/np.sum(pos_truei, axis=(1,2)) * 160,\n",
    "        led_true = np.sum(led_truei * pos_truei, axis=(1,2))/np.sum(pos_truei, axis=(1,2)),\n",
    "        dis_true = np.sum(dis_truei * pos_truei, axis=(1,2))/np.sum(pos_truei, axis=(1,2)),\n",
    "    )\n",
    "    return [dict(zip(ret,t)) for t in zip(*ret.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822c34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_out = []\n",
    "with torch.no_grad():\n",
    "    for data in valid_dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_tq_removed(inputs.float())\n",
    "        outputs = outputs * torch.tensor([1., 1., 3.]).view(1, 3, 1, 1).to(outputs.device)\n",
    "        data_out += postprocess_simple_batch(labels,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916af2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_out)\n",
    "df[\"y_zone\"] = (df[\"y_true\"]/320*3).astype(int)\n",
    "df[\"pred_confidence_bin\"] = (df[\"pred_confidence\"]*2.99).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465716d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "fig,axs = plt.subplots(ncols=3, figsize=(10,3))\n",
    "alpha = 0.1\n",
    "axs[0].scatter(df[\"x_true\"],df[\"x_pred\"], s=1, marker='.', alpha=alpha)\n",
    "axs[0].plot([0,160],[0,160],'k:')\n",
    "axs[0].set_title(f\"u: R2 {sklearn.metrics.r2_score(df['x_true'],df['x_pred']):.03f}\")\n",
    "axs[1].scatter(df[\"y_true\"],df[\"y_pred\"], s=1, marker='.', alpha=alpha)\n",
    "axs[1].plot([0,160],[0,160],'k:')\n",
    "axs[1].set_title(f\"v: R2 {sklearn.metrics.r2_score(df['y_true'],df['y_pred']):.03f}\")\n",
    "axs[2].scatter(df[\"dis_true\"],df[\"dis_pred\"]/(255*0.5), s=1, marker='.', alpha=alpha)\n",
    "axs[2].plot([0.4,1.6],[0.4,1.6],'k:')\n",
    "axs[2].set_title(f\"d: R2 {sklearn.metrics.r2_score(df['dis_true'],df['dis_pred']/(255*0.5)):.03f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031660a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib.pyplot import figure\n",
    "font = {'family' : 'normal',\n",
    "'weight' : 'bold',\n",
    "'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "figure(figsize=(8,8), dpi=80)\n",
    "plt.title(\"distance\")\n",
    "plt.xlim([0.2, 1.6])\n",
    "plt.ylim([0.2, 1.6])\n",
    "plt.plot(df[\"dis_true\"],df[\"dis_true\"], c =\"green\")\n",
    "plt.scatter(df[\"dis_true\"],df[\"dis_pred\"]/(255*0.5), c =\"red\", alpha=0.1)\n",
    "plt.show()\n",
    "figure(figsize=(8,8), dpi=80)\n",
    "plt.title(\"v image\")\n",
    "plt.xlim([0, 160])\n",
    "plt.ylim([0, 160])\n",
    "plt.plot(df[\"y_true\"],df[\"y_true\"], c =\"green\")\n",
    "plt.scatter(df[\"y_true\"], df[\"y_pred\"], c =\"red\", alpha=0.1)\n",
    "plt.show()\n",
    "figure(figsize=(8,8), dpi=80)\n",
    "plt.title(\"u image\")\n",
    "plt.xlim([0, 160])\n",
    "plt.ylim([0, 160])\n",
    "plt.plot(df[\"x_true\"], df[\"x_true\"], c =\"green\")\n",
    "plt.scatter(df[\"x_true\"], df[\"x_pred\"], c =\"red\", alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083ab46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = get_data(\"./content/datasets_test_hard/dataset_test_hard.h5\",False,False,0)\n",
    "test_dataset = MyDataset(test_set[0], test_set[1])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb65706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_tq_removed(inputs.float())\n",
    "        outputs = outputs * torch.tensor([1., 1., 3.]).view(1, 3, 1, 1).to(outputs.device)\n",
    "        data_out += postprocess_simple_batch(labels,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13575ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_out)\n",
    "df[\"y_zone\"] = (df[\"y_true\"]/320*3).astype(int)\n",
    "df[\"pred_confidence_bin\"] = (df[\"pred_confidence\"]*2.99).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "fig,axs = plt.subplots(ncols=3, figsize=(10,3))\n",
    "alpha = 0.1\n",
    "axs[0].scatter(df[\"x_true\"],df[\"x_pred\"], s=1, marker='.', alpha=alpha)\n",
    "axs[0].plot([0,160],[0,160],'k:')\n",
    "axs[0].set_title(f\"u: R2 {sklearn.metrics.r2_score(df['x_true'],df['x_pred']):.03f}\")\n",
    "axs[1].scatter(df[\"y_true\"],df[\"y_pred\"], s=1, marker='.', alpha=alpha)\n",
    "axs[1].plot([0,160],[0,160],'k:')\n",
    "axs[1].set_title(f\"v: R2 {sklearn.metrics.r2_score(df['y_true'],df['y_pred']):.03f}\")\n",
    "axs[2].scatter(df[\"dis_true\"],df[\"dis_pred\"], s=1, marker='.', alpha=alpha)\n",
    "axs[2].plot([0.4,1.6],[0.4,1.6],'k:')\n",
    "axs[2].set_title(f\"d: R2 {sklearn.metrics.r2_score(df['dis_true'],df['dis_pred']/(255*0.5)):.03f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9efe3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib.pyplot import figure\n",
    "font = {'family' : 'normal',\n",
    "'weight' : 'bold',\n",
    "'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "figure(figsize=(8,8), dpi=80)\n",
    "plt.title(\"distance\")\n",
    "plt.xlim([0.2, 1.6])\n",
    "plt.ylim([0.2, 1.6])\n",
    "plt.plot(df[\"dis_true\"],df[\"dis_true\"], c =\"green\")\n",
    "plt.scatter(df[\"dis_true\"],df[\"dis_pred\"]/(255*0.5), c =\"red\", alpha=0.1)\n",
    "plt.show()\n",
    "figure(figsize=(8,8), dpi=80)\n",
    "plt.title(\"v image\")\n",
    "plt.xlim([0, 160])\n",
    "plt.ylim([0, 160])\n",
    "plt.plot(df[\"y_true\"],df[\"y_true\"], c =\"green\")\n",
    "plt.scatter(df[\"y_true\"], df[\"y_pred\"], c =\"red\", alpha=0.1)\n",
    "plt.show()\n",
    "figure(figsize=(8,8), dpi=80)\n",
    "plt.title(\"u image\")\n",
    "plt.xlim([0, 160])\n",
    "plt.ylim([0, 160])\n",
    "plt.plot(df[\"x_true\"], df[\"x_true\"], c =\"green\")\n",
    "plt.scatter(df[\"x_true\"], df[\"x_pred\"], c =\"red\", alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae1753-3287-4800-b4d9-8779691d2d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
